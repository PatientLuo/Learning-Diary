[
  {
    "objectID": "Week1.html",
    "href": "Week1.html",
    "title": "1¬† Week 1 Learning Diary",
    "section": "",
    "text": "2 üåç Week1",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Week 1 Learning Diary</span>"
    ]
  },
  {
    "objectID": "Week1.html#summary",
    "href": "Week1.html#summary",
    "title": "1¬† Week 1 Learning Diary",
    "section": "2.1 Summary",
    "text": "2.1 Summary\nThis week‚Äôs course introduces the basic concepts and methods of remote sensing (Remote Sensing). Remote sensing refers to the technology of obtaining information about the Earth from a distance, usually with the help of sensors on platforms such as satellites, aircraft or drones (Campbell and Wynne, 2011). We discussed in depth the difference between active and passive remote sensing: active remote sensing uses signals emitted by itself (e.g.¬†radar, lidar, etc.) and receives reflected information, while passive remote sensing relies on information reflected from sunlight hitting the surface, such as the Landsat and Sentinel satellites (Jensen, 2009).\nRemote sensing data usually have four types of resolution: spatial resolution (pixel size), spectral resolution (number of detected bands), temporal resolution (revisit period) and radiometric resolution (sensitivity of detected spectra). These resolutions determine the application range and accuracy of remote sensing data. At the same time, the electromagnetic spectral signature (Spectral Signature) of the Earth‚Äôs surface enables remote sensing technology to effectively differentiate between different feature types, such as vegetation, water bodies, and soils. In addition, we discussed that the acquisition of remote sensing data may be affected by atmospheric conditions such as clouds and haze, which makes it necessary to ensure the quality and validity of data through atmospheric correction and other means (Schowengerdt, 2007).",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Week 1 Learning Diary</span>"
    ]
  },
  {
    "objectID": "Week1.html#applications",
    "href": "Week1.html#applications",
    "title": "1¬† Week 1 Learning Diary",
    "section": "2.2 Applications",
    "text": "2.2 Applications\nRemote sensing technology has in fact long permeated every aspect of our lives, especially in the matter of responding to natural disasters, where its role is becoming increasingly important. For example, the synthetic aperture radar (SAR) in active remote sensing, which we mentioned in class, is particularly powerful in flood detection. Traditional optical satellites are easily blocked by clouds, but SAR is different, it can ‚Äòpenetrate‚Äô the clouds to monitor the ground conditions around the clock, so it is particularly useful in emergency situations such as floods (Amitrano et al., 2024). A recent reading also highlights that with climate change and increased urbanisation, flooding is becoming more frequent, making it vital to be able to identify and monitor flooded areas quickly and effectively, a need that SAR data meets, and one that can help governments to respond quickly and allocate resources for disaster relief(Twele et al., 2016).\n\n\n\nFig. 1 Three types of scattering of radar signals\n\n\nSource: Amitrano et al.¬†(2024)\nIn addition to flood monitoring, passive remote sensing data are also widely used, such as the Landsat and Sentinel-2 satellites that we often hear about, and their applications in agriculture and the ecological environment are particularly numerous. As an example, satellite data can be used to calculate the vegetation index (NDVI), which helps the agricultural sector to more accurately assess the growth of crops and predict yields, and can even monitor changes in the ecological environment in real time. Moreover, using cloud computing platforms such as Google Earth Engine, people can easily analyse large-scale land cover changes and even monitor global ecological trends (Zhu and Woodcock, 2014; Gorelick et al., 2017).\n\n\n\nFigure 2 Schematic of the Google Earth Engine\n\n\nSource: Gorelick et al.¬†(2017)\nHowever, remote sensing is not a panacea, especially in cities and areas with vegetation cover, where SAR data can still be difficult to analyse. This is because buildings and vegetation in cities can cause complex signal reflections, making accurate identification of flooded areas tricky at times. Overall, however, the convenience and comprehensiveness provided by remote sensing data gives us more initiative in disaster response and environmental management, and the future development prospects are still worth looking forward to.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Week 1 Learning Diary</span>"
    ]
  },
  {
    "objectID": "Week1.html#reflection",
    "href": "Week1.html#reflection",
    "title": "1¬† Week 1 Learning Diary",
    "section": "2.3 Reflection",
    "text": "2.3 Reflection\nThe first week of remote sensing class made me realise right away that this technology is not just an abstract theory in the academic field, but a real tool that can make a difference in people‚Äôs lives. Of interest to me was the fact that active remote sensing (SAR), which we mentioned in class, has particularly prominent applications in natural disaster, especially flood monitoring. My previous understanding of remote sensing may have been limited to the simple application of satellite imagery, but I had no idea that it also has such great potential to address the risks associated with urbanisation and to protect people‚Äôs lives and property.\nAt the same time, I also noticed that although SAR can overcome the shortcomings of traditional optical images (such as the influence of cloud cover), there are still some challenges in its practical application. For example, the processing of SAR data in complex environments such as cities is still difficult, which reminds me that there are still quite a few practical problems to overcome between the development of the technology and the landing of the application. In addition, I am particularly interested in cloud platforms such as Google Earth Engine, which greatly reduces the threshold of remote sensing data analysis and allows us to quickly carry out large-scale environmental monitoring on a global scale, which is very attractive for both academic research and practical work.\nOne of the deepest feelings I got from this class is that remote sensing technology has really brought people closer to the Earth‚Äôs environment. Although there are still a lot of technical details that I need to learn in depth, I am already looking forward to what I can learn next and the role this knowledge can play in my future studies and career.\n\n\n\n\nAmitrano, D. et al. (2024) ‚ÄúFlood detection with SAR: A review of techniques and datasets,‚Äù Remote Sensing, 16(4), p. 656. Available at: https://doi.org/10.3390/rs16040656.\n\n\nCampbell, J.B. and Wynne, R.H. (2011) Introduction to remote sensing. 5th ed. Guilford Press.\n\n\nGorelick, N. et al. (2017) ‚ÄúGoogle earth engine: Planetary-scale geospatial analysis for everyone,‚Äù Remote Sensing of Environment, 202, pp. 18‚Äì27. Available at: https://doi.org/10.1016/j.rse.2017.06.031.\n\n\nJensen, J.R. (2009) Remote sensing of the environment: An earth resource perspective. 2nd ed. Pearson Education India.\n\n\nSchowengerdt, R.A. (2007) Remote sensing: Models and methods for image processing. 3rd ed. Academic Press.\n\n\nTwele, A. et al. (2016) ‚ÄúSentinel-1-based flood mapping: A fully automated processing chain,‚Äù International Journal of Remote Sensing, 37(13), pp. 2990‚Äì3004. Available at: https://doi.org/10.1080/01431161.2016.1192304.\n\n\nZhu, Z. and Woodcock, C.E. (2014) ‚ÄúContinuous change detection and classification of land cover using all available landsat data,‚Äù Remote Sensing of Environment, 144, pp. 152‚Äì171. Available at: https://doi.org/10.1016/j.rse.2014.01.011.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Week 1 Learning Diary</span>"
    ]
  },
  {
    "objectID": "Week3.html",
    "href": "Week3.html",
    "title": "3¬† Week 3 Learning Diary",
    "section": "",
    "text": "3.1 üì¢ Week 3: Learning Corrections",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Week 3 Learning Diary</span>"
    ]
  },
  {
    "objectID": "Week3.html#summary",
    "href": "Week3.html#summary",
    "title": "3¬† Week 3 Learning Diary",
    "section": "3.2 Summary",
    "text": "3.2 Summary\nThis week‚Äôs course took us on an in-depth exploration of important data correction methods and technical background in remote sensing data processing. First, we reviewed the history of the famous Landsat series of satellite data, with a special focus on the key contributions of technician Virginia Norwood, whose design of the digital multispectral scanner (Multispectral Scanner (MSS)) replaced the traditional analogue camera technique and drove a major change in remote sensing technology. Today, Norwood‚Äôs Whisk broom scanning technique is at the heart of remote sensing data acquisition.\nIn terms of data processing, we specifically learnt about three key methods, namely geometric correction, atmospheric correction and orthometric correction. Geometric correction addresses the spatial error between the satellite image and the actual geographic location by calibrating the image position through Ground Control Points (GCPs). Atmospheric correction deals with the data bias caused by the atmosphere, including relative correction (e.g.¬†dark object subtraction, pseudo-invariant feature method) and absolute correction (e.g.¬†FLAASH model) to ensure that the acquired data reflect the surface conditions more realistically. Orthometric corrections are used to correct image distortions caused by the angle of observation of the satellite, using mathematical models and surface elevation data to produce an accurate image as if viewed from directly above.\n\nSummary of Remote Sensing Data Corrections\n\n\n\n\n\n\n\n\n\n\nCorrection Method\nMain Purpose\nCommon Techniques\n\n\n\n\nGeometric Correction\nEnsures spatial accuracy of images\nGround Control Points (GCP)\n\n\nAtmospheric Correction\nRemoves atmospheric interference (clouds, haze, etc.)\n- Relative Correction: Dark Object Subtraction, Pseudo-Invariant Feature Method - Absolute Correction: FLAASH Model\n\n\nOrthorectification\nEliminates distortions caused by satellite viewing angles\nMathematical models, DEM-based corrections\n\n\n\n\n\n\n                \nThrough this week‚Äôs study, I have gained a deep understanding of the complexity behind the process of remote sensing data processing, the seemingly tedious but very important steps that ensure the efficiency and accuracy of the data in scientific research and practical applications, and enable us to use remote sensing data more confidently in analyses and decision-making.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Week 3 Learning Diary</span>"
    ]
  },
  {
    "objectID": "Week3.html#application",
    "href": "Week3.html#application",
    "title": "3¬† Week 3 Learning Diary",
    "section": "3.3 Application",
    "text": "3.3 Application\nAfter studying the remote sensing data correction techniques during the week, I purposely reviewed some examples of remote sensing correction applications in practical research, which helped me better understand the practical value of these methods. For example, in crop estimation studies, atmospheric correction techniques have a significant impact on the accuracy of vegetation indices. The accuracy of NDVI data can be significantly improved by accurate atmospheric correction, which can better monitor the true health of crops and thus help farmers to increase yields and reduce losses (Song et al. (2001)). In addition, some studies have also clearly pointed out that remote sensing data without correct geometric correction may lead to significant overestimation or underestimation of forest fire area (Roy et al. (2016)). Therefore, the importance of accurate geometric correction in the field of disaster management cannot be overstated.\nThe application of orthometric correction, on the other hand, reminds me of practical examples in urban planning. For example, in urban expansion studies, image distortion caused by satellite image tilting can seriously affect the accurate measurement of urban area, which can be effectively avoided after accurate ortho-correction, helping decision makers to grasp urban expansion trends more accurately (Lefebvre, Sannier and Corpetti (2016)). This study used Sentinel-2 data to update the Copernicus High Resolution Impermeable Layer (HRL IMD), which improves the accuracy of urban change monitoring through remote sensing data fusion, as exemplified in the figure below which detects the changes in the city of Rennes for the years 2012-2015. This shows that orthorectification is not only applicable to traditional geographic studies, but also plays a crucial role in modern large-scale urban monitoring missions.\n\n\n\nUrban Change Detection in Rennes (2012-2015)\nSource: Lefebvre, Sannier and Corpetti (2016)\n\n\nThrough these application cases, I also began to think that although the methods we learnt in class are very mature, in practice, we still need to flexibly adjust the calibration strategy according to specific research scenarios. After all, disturbances in real environments are often more complex. This also inspired me to pay more attention to the flexibility and applicability of remote sensing methods in my future study and research.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Week 3 Learning Diary</span>"
    ]
  },
  {
    "objectID": "Week3.html#reflection",
    "href": "Week3.html#reflection",
    "title": "3¬† Week 3 Learning Diary",
    "section": "3.4 Reflection",
    "text": "3.4 Reflection\nThrough this week‚Äôs study, I deeply feel that remote sensing data processing is not simply a matter of ‚Äòtaking a picture‚Äô, but requires a lot of rigorous and detailed technical processing and correction steps behind it. In the past, I always thought that satellite images were just taken and used directly, but now I realise that this is just the beginning of the data processing journey. From data acquisition to real application, every step in between - be it geometric, atmospheric or orthometric correction - must be rigorously executed to ensure the accuracy and usability of the final data.\nI was struck by the fact that these seemingly complex and trivial steps all lead to a common goal: to ensure that we make the right decisions when facing environmental problems. For example, through accurate atmospheric corrections, we can obtain more accurate data on vegetation cover and thus plan for ecological protection more effectively. In addition, thinking about current technological developments, such as the increasing maturity of cloud computing platforms and automated processing technologies, I am also confident that in the future these data processing processes will become more streamlined and efficient, and our research and decision-making processes will become more reliable and timely. This anticipation of the future makes me even more enthusiastic and motivated for the subsequent courses and exploration of remote sensing technology.\n\n\n\n\nLefebvre, A., Sannier, C. and Corpetti, T. (2016) ‚ÄúMonitoring urban areas with sentinel-2A data: Application to the update of the copernicus high resolution layer imperviousness degree,‚Äù Remote Sensing, 8(7), p. 606. Available at: https://doi.org/10.3390/rs8070606.\n\n\nRoy, D.P. et al. (2016) ‚ÄúThe collection 5 MODIS burned area product‚Äîglobal evaluation by comparison with the MODIS active fire product,‚Äù Remote Sensing of Environment, 112(9), pp. 3690‚Äì3707. Available at: https://doi.org/10.1016/j.rse.2008.05.013.\n\n\nSong, C. et al. (2001) ‚ÄúClassification and change detection using landsat TM data: When and how to correct atmospheric effects?‚Äù Remote Sensing of Environment, 75(2), pp. 230‚Äì244. Available at: https://doi.org/10.1016/S0034-4257(00)00169-3.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Week 3 Learning Diary</span>"
    ]
  },
  {
    "objectID": "Week2.html",
    "href": "Week2.html",
    "title": "2¬† Week 2 Learning Diary",
    "section": "",
    "text": "2.1 Week2\nüì¢ Week 2: Creating PPTs with xaringan This week, we will be using xaringan, an R Markdown package, to create slides. xaringan allows us to build flexible, interactive, and beautifully styled presentations using simple Markdown syntax. It‚Äôs a powerful tool for sharing research findings, data visualizations, and spatial analysis results in a professional and customizable way.\nThroughout this week, we will explore how to: ‚úÖ Set up a basic xaringan presentation ‚úÖ Customize themes and layouts ‚úÖ Integrate code, plots, and interactive elements\nI‚Äôm excited to dive into this and see how we can make engaging presentations with xaringan! üöÄ",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Week 2 Learning Diary</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning-Diary1",
    "section": "",
    "text": "Welcome!\nHi everyone! I‚Äôm Luo Huangchen, currently pursuing a master‚Äôs degree in Urban Spatial Science, with a focus on transportation planning, spatial data analysis, and remote sensing applications. I enjoy using data to tell stories and exploring new technologies to make cities smarter and more livable. During my undergraduate years, I participated in various projects related to smart transportation, sustainable urban development, and traffic system optimization. I‚Äôve worked extensively with tools like ArcGIS, Python, and R for data analysis. Recently, I‚Äôve been researching mangrove and wetland conservation in the Greater Bay Area using remote sensing, which has been both challenging and exciting! Beyond academics, I love traveling, photography, and trying new things. I often optimize SQL queries, simulate traffic flows with VISSIM, and conduct spatial analyses with GIS. Of course, I also take some time to relax by watching shows and unwinding. üòÜ I‚Äôm looking forward to connecting with like-minded people and exploring the fascinating world of cities together! I‚Äôm really passionate about remote sensing, and I‚Äôm excited to learn and gain more knowledge in CASA0023. I‚Äôm looking forward to all the lectures and workshops!\n```",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "Week2.html#sentinel-2-xaringan-presentation",
    "href": "Week2.html#sentinel-2-xaringan-presentation",
    "title": "2¬† Week 2 Learning Diary",
    "section": "2.2 üéûÔ∏è Sentinel-2 Xaringan Presentation",
    "text": "2.2 üéûÔ∏è Sentinel-2 Xaringan Presentation\nBelow is my Week 2 interactive presentation created using xaringan and hosted on GitHub Pages.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Week 2 Learning Diary</span>"
    ]
  },
  {
    "objectID": "Week6.html",
    "href": "Week6.html",
    "title": "5¬† Week 6 Diary",
    "section": "",
    "text": "6 Week6",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Week 6 Diary</span>"
    ]
  },
  {
    "objectID": "Week6.html#summary-classification-in-remote-sensing",
    "href": "Week6.html#summary-classification-in-remote-sensing",
    "title": "5¬† Week 6 Diary",
    "section": "6.1 Summary: Classification in Remote Sensing",
    "text": "6.1 Summary: Classification in Remote Sensing\nIn this week‚Äôs course, we learnt about Google Earth Engine (GEE), a widely used cloud computing platform in remote sensing, which is a geospatial analysis platform based on cloud computing technology launched by Google. The most important feature of GEE is that it can process large-scale remote sensing data online in real time, helping researchers to easily analyse and visualise complex geospatial data without being limited to the performance constraints of local computers (Gorelick et al., 2017).\nThe course highlights the difference between two key concepts of GEE data processing: client-side and server-side. Client-side processing relies on the performance of the user‚Äôs own computer and is suitable for simple tasks, whereas server-side processing takes advantage of the powerful computing capabilities of the Google Cloud and can efficiently parallelise complex tasks. This means that we should use server-side functions whenever possible when using GEE to improve processing efficiency (Mutanga and Kumar, 2019).\nIn practice, we learnt the data filtering methods of GEE, such as filterDate() (time range filtering) and filterBounds() (spatial range filtering). Proper use of these filtering methods can significantly reduce the amount of computation and avoid unnecessary data downloads and memory errors (Gorelick et al., 2017). In addition, the data visualisation function of GEE is powerful; by adjusting the appropriate spatial resolution and band combination, we can quickly view the features of satellite images, such as vegetation, water bodies or urban areas.\nData reduction and statistical analysis is also one of the important functions of GEE. We specifically learnt about zonal statistics and image reduction. Zonal statistics, such as the reduceRegion() function, can easily calculate the Normalized Difference Vegetation Index (NDVI) or rainfall for a specific region, which is widely used in agricultural monitoring and ecological research (Amani et al., 2020). Image downscaling can use methods such as median() or mean() to efficiently handle large amounts of data, thus reducing the computational resources required for analysis.\nTaken together, this week‚Äôs course demonstrates how the combination of cloud computing and remote sensing technology has significantly lowered the technical barrier to remote sensing analysis and increased the availability and efficiency of data analysis.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Week 6 Diary</span>"
    ]
  },
  {
    "objectID": "Week6.html#application",
    "href": "Week6.html#application",
    "title": "5¬† Week 6 Diary",
    "section": "6.2 Application",
    "text": "6.2 Application\nGoogle Earth Engine (GEE) has been widely used in many fields, such as environmental monitoring, agricultural production management, climate change analysis and disaster response, due to its powerful cloud computing capability and rich data resources.\nOne of the application cases that impresses me is the long-term monitoring of land cover changes using the GEE platform. In this week‚Äôs reading, I learnt about a study on high-resolution analysis of global forest change based on GEE. The study took full advantage of GEE‚Äôs cloud computing and processed more than 650,000 Landsat satellite images, resulting in fine-grained monitoring of forest change on a global scale.\nIn the past, this type of global-scale big data processing was often extremely time-consuming, but with the capability of GEE, the efficiency and accuracy of the study can be greatly improved (Hansen et al., 2013).\n\n\n\n\n\nFig. 1 Regional examples of forest cover change from 2000 to 2012\nSource: Hansen et al.¬†(2013)\nNot only forest monitoring, GEE has important applications in disaster response. For example, flood monitoring, in the past, when floods occurred, it has been a challenge to obtain timely information about the affected area. Maps of flood-affected areas can be quickly generated by GEE, which significantly improves the efficiency of disaster response operations (DeVries et al., 2017). Specifically, Sentinel-1 radar imagery can be rapidly analysed on the GEE platform, which is able to ‚Äòcut through‚Äô clouds and bad weather, providing accurate and timely data to support relief operations even under adverse weather conditions.\n\n\n\n\n\nFig. 2 Flowchart of the SWF estimation algorithm demonstrated in this study\nSource: DeVries et al.¬†(2017)\nIn addition, I am particularly interested in the application of GEE in agriculture. We can use the GEE platform to monitor the production of corn in the Midwest region of the U.S. in real time, and by calculating the vegetation indices (e.g., NDVI) in satellite images, we have established a crop yield prediction model (Azzari and Lobell, 2017). This method is more timely and accurate than traditional ground observation, and can help the agricultural sector make decisions in advance and optimise resource allocation.\n\n\n\n\n\nFig. 3 Samples of the different cover types as seen in Google Earth high-resolution images:\n(a) rainfed crops (RFC),\n(b) irrigated crops (IRC),\n(c) urban areas (URB),\n(d) swamp natural vegetation (SWN),\n(e) open-canopy natural vegetation (OCN),\n(f) close-canopy natural vegetation (CCN).\nSource: Azzari and Lobell (2017)\nIn my opinion, the emergence of GEE is not only a technological advancement, but also a change in the way of thinking. In the past, remote sensing analyses were often limited by local computing resources, and researchers had to consider how to compress the data or reduce the precision of the analyses. Now, with GEE‚Äôs cloud computing capabilities, we can be bolder in designing research programmes and attempting more complex and comprehensive data analysis. This shift means that remote sensing technology will play an even more critical role in solving major global problems.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Week 6 Diary</span>"
    ]
  },
  {
    "objectID": "Week6.html#reflection",
    "href": "Week6.html#reflection",
    "title": "5¬† Week 6 Diary",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\nThe biggest feeling I got from learning Google Earth Engine (GEE) this week is that technology is really changing the research possibilities. In the past, remote sensing data processing often faced the problem of insufficient computing resources, especially when we tried to process large-scale satellite image data, the local computer would soon ‚Äòstrike‚Äô, but now just open the GEE platform, many analyses that used to be inconceivable instantly become feasible. This convenience really makes me feel that my research is full of more possibilities and I have more confidence to try new research methods.\nHowever, I also realised that although GEE looks wonderful, it is not entirely without difficulties in practice. For example, how to use some built-in functions or datasets efficiently still needs to be further explored; at the same time, once Google changes the platform functionality, our code may suddenly ‚Äòfail‚Äô. This requires us to keep track of the analysis process, regularly check for code updates, and adapt to new changes in the platform in a timely manner.\nOverall, this study not only helped me to master a powerful analysis tool, but also made me start to think about the relationship between technology and research. The tool is only an aid, and how to effectively integrate this tool into concrete research may be more worthwhile for me to think about in depth in the future. I am also looking forward to using GEE to try to solve some real environmental problems in my future courses or research, so that I can really apply what I have learnt to real scenarios.\n\n\n\n\nAmani, M. et al. (2020) ‚ÄúGoogle earth engine cloud computing platform for remote sensing big data applications: A comprehensive review,‚Äù IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 13, pp. 5326‚Äì5350. Available at: https://doi.org/10.1109/JSTARS.2020.3021052.\n\n\nAzzari, G. and Lobell, D.B. (2017) ‚ÄúLandsat-based classification in the cloud: An opportunity for a paradigm shift in land cover monitoring,‚Äù Remote Sensing of Environment, 202, pp. 64‚Äì74. Available at: https://doi.org/10.1016/j.rse.2017.05.025.\n\n\nDeVries, B. et al. (2017) ‚ÄúAutomated quantification of surface water inundation in wetlands using optical satellite imagery,‚Äù Remote Sensing, 9(8), p. 807. Available at: https://doi.org/10.3390/rs9080807.\n\n\nGorelick, N. et al. (2017) ‚ÄúGoogle earth engine: Planetary-scale geospatial analysis for everyone,‚Äù Remote Sensing of Environment, 202, pp. 18‚Äì27. Available at: https://doi.org/10.1016/j.rse.2017.06.031.\n\n\nHansen, M.C. et al. (2013) ‚ÄúHigh-resolution global maps of 21st-century forest cover change,‚Äù Science, 342(6160), pp. 850‚Äì853. Available at: https://doi.org/10.1126/science.1244693.\n\n\nMutanga, O. and Kumar, L. (2019) ‚ÄúGoogle earth engine applications,‚Äù Remote Sensing, 11(5), p. 591. Available at: https://doi.org/10.3390/rs11050591.",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Week 6 Diary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Amani, M. et al. (2020) ‚ÄòGoogle earth engine cloud\ncomputing platform for remote sensing big data applications: A\ncomprehensive review‚Äô, IEEE Journal of Selected Topics in\nApplied Earth Observations and Remote Sensing, 13, pp. 5326‚Äì5350.\nAvailable at: https://doi.org/10.1109/JSTARS.2020.3021052.\n\n\nAmitrano, D. et al. (2024) ‚ÄòFlood detection with SAR: A\nreview of techniques and datasets‚Äô, Remote Sensing,\n16(4), p. 656. Available at: https://doi.org/10.3390/rs16040656.\n\n\nAzzari, G. and Lobell, D.B. (2017) ‚ÄòLandsat-based classification\nin the cloud: An opportunity for a paradigm shift in land cover\nmonitoring‚Äô, Remote Sensing of Environment, 202, pp.\n64‚Äì74. Available at: https://doi.org/10.1016/j.rse.2017.05.025.\n\n\nCampbell, J.B. and Wynne, R.H. (2011) Introduction to remote\nsensing. 5th edn. Guilford Press.\n\n\nGorelick, N. et al. (2017) ‚ÄòGoogle earth engine:\nPlanetary-scale geospatial analysis for everyone‚Äô, Remote\nSensing of Environment, 202, pp. 18‚Äì27. Available at: https://doi.org/10.1016/j.rse.2017.06.031.\n\n\nHansen, M.C. et al. (2013) ‚ÄòHigh-resolution global maps\nof 21st-century forest cover change‚Äô, Science,\n342(6160), pp. 850‚Äì853. Available at: https://doi.org/10.1126/science.1244693.\n\n\nJensen, J.R. (2009) Remote sensing of the environment: An earth\nresource perspective. 2nd edn. Pearson Education India.\n\n\nKnuth, D.E. (1984) ‚ÄòLiterate programming‚Äô, Comput.\nJ., 27(2), pp. 97‚Äì111. Available at: https://doi.org/10.1093/comjnl/27.2.97.\n\n\nLefebvre, A., Sannier, C. and Corpetti, T. (2016) ‚ÄòMonitoring\nurban areas with sentinel-2A data: Application to the update of the\ncopernicus high resolution layer imperviousness degree‚Äô,\nRemote Sensing, 8(7), p. 606. Available at: https://doi.org/10.3390/rs8070606.\n\n\nMutanga, O. and Kumar, L. (2019) ‚ÄòGoogle earth engine\napplications‚Äô, Remote Sensing, 11(5), p. 591. Available\nat: https://doi.org/10.3390/rs11050591.\n\n\nRoy, D.P. et al. (2016) ‚ÄòThe collection 5 MODIS burned\narea product‚Äîglobal evaluation by comparison with the MODIS active fire\nproduct‚Äô, Remote Sensing of Environment, 112(9), pp.\n3690‚Äì3707. Available at: https://doi.org/10.1016/j.rse.2008.05.013.\n\n\nSchowengerdt, R.A. (2007) Remote sensing: Models and methods for\nimage processing. 3rd edn. Academic Press.\n\n\nSong, C. et al. (2001) ‚ÄòClassification and change\ndetection using landsat TM data: When and how to correct atmospheric\neffects?‚Äô, Remote Sensing of Environment, 75(2), pp.\n230‚Äì244. Available at: https://doi.org/10.1016/S0034-4257(00)00169-3.\n\n\nTwele, A. et al. (2016) ‚ÄòSentinel-1-based flood mapping:\nA fully automated processing chain‚Äô, International Journal of\nRemote Sensing, 37(13), pp. 2990‚Äì3004. Available at: https://doi.org/10.1080/01431161.2016.1192304.\n\n\nZhu, Z. and Woodcock, C.E. (2014) ‚ÄòContinuous change detection and\nclassification of land cover using all available landsat data‚Äô,\nRemote Sensing of Environment, 144, pp. 152‚Äì171. Available at:\nhttps://doi.org/10.1016/j.rse.2014.01.011.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "Week7.html",
    "href": "Week7.html",
    "title": "6¬† Week 7 Diary",
    "section": "",
    "text": "7 Week 7: Classification Methods and Applications",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Week 7 Diary</span>"
    ]
  },
  {
    "objectID": "Week7.html#summary",
    "href": "Week7.html#summary",
    "title": "6¬† Week 7 Diary",
    "section": "7.1 Summary",
    "text": "7.1 Summary\nThis week‚Äôs course focuses on the key methods and principles of remote sensing classification, especially the difference between Supervised Classification and Unsupervised Classification and their application scenarios. In Supervised Classification, we mainly studied Decision Tree and Random Forest algorithms. The professor emphasised that Decision Tree has the advantage of being intuitive and easy to understand, but it is also prone to overfitting, i.e.¬†the model may be too sensitive to the training data and difficult to generalise to new data. To solve this problem, we also learnt the Random Forest method, which not only improves classification accuracy but also effectively reduces the risk of overfitting by integrating the results of multiple decision trees.\nAnother highlight of the course was the introduction of Regression Tree. While most of the classification algorithms we have come across in the past are for prediction of discrete categories, Regression Tree is able to deal with continuous variables, such as the estimation of the proportion of vegetation in land cover. The professor mentioned that regression trees are similar in principle to decision trees, but use numerical variables rather than category labels in node splitting, making them ideal for more refined environmental monitoring tasks.\nIn terms of unsupervised classification, we instead focused on K-means clustering methods. Instead of pre-labelling the training samples, this method automatically groups pixels based on the spectral features of the data, which is particularly useful in scenarios where explicitly labelled data is lacking. However, the professor also pointed out that K-means requires manual judgement of the optimal number of categories in practical applications, which adds to the subjectivity in its use.\nThrough this week‚Äôs study, I further realised the importance of the choice of classification method: supervised classification is suitable for situations with sufficient training data, while unsupervised classification is suitable for exploratory analysis or scenarios with limited data. Overall, this week has given me a better understanding of how to choose the most appropriate classification tool for my actual needs.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Week 7 Diary</span>"
    ]
  },
  {
    "objectID": "Week7.html#applications",
    "href": "Week7.html#applications",
    "title": "6¬† Week 7 Diary",
    "section": "7.2 Applications",
    "text": "7.2 Applications\nThe supervised and unsupervised classification methods I learned in this week‚Äôs course got me thinking about how I can apply them more effectively to real-world remote sensing research.\nFirstly, for supervised classification, I think the Random Forest algorithm has great potential. Compared with traditional decision trees, it significantly improves classification accuracy through the voting mechanism of multiple trees and mitigates the risk of overfitting, which is especially suitable for complex remote sensing analysis of urban environments. After reviewing the relevant literature, I found that the Random Forest approach has been widely used in monitoring urban land use changes and has demonstrated extremely high accuracy. For example, one study used the Random Forest algorithm to analyse Sentinel-2 imagery and successfully identified different land use types in the process of urban expansion, which was significantly better than the classification results of a single decision tree (Belgiu and DrƒÉgu≈£, 2016).\n\n\n\n\n\nFig. 1 Training and classification phases of Random Forest classifier\nSource: Belgiu and DrƒÉgu≈£ (2016)\nOn the other hand, the introduction of regression trees also reminded me of their potential for analysing urban vegetation and environmental indicators. I found that regression trees are particularly suitable for estimating continuous environmental variables, such as the proportion of vegetation cover within a city or the distribution of urban surface temperature. In past studies, regression trees have been successfully used to quantitatively analyse urban heat island intensity from remote sensing imagery, helping urban planning authorities to accurately identify areas with temperature anomalies (Imhoff et al., 2010).\n\n\n\n\n\nFig. 2 Urban Heat Island Intensity and Spatial Distribution Across Different Biomes in the USA\nSource: Imhoff et al.¬†(2010)\nIn addition, for cases where the data lacks explicit labelling, I believe that unsupervised classification methods such as K-means clustering are equally valuable. K-means can automatically identify feature types based on spectral similarity without predefined categories. This is useful for initial exploration of new remote sensing datasets or in areas where detailed ground data are lacking. However, the number of categories for K-means needs to be determined by humans, which may introduce some subjectivity. I note that some studies have used K-means for initial classification in urban landscape analyses, which was subsequently combined with a small amount of supervised data for fine-grained corrections, resulting in more accurate classification results (Gao and Xu, 2016). This strategy of combining unsupervised and supervised classification is worth trying in depth in my future.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Week 7 Diary</span>"
    ]
  },
  {
    "objectID": "Week7.html#reflection",
    "href": "Week7.html#reflection",
    "title": "6¬† Week 7 Diary",
    "section": "7.3 Reflection",
    "text": "7.3 Reflection\nThis week‚Äôs study on classification methods in remote sensing has made me further appreciate the ‚Äòart of choice‚Äô behind the analysis of remote sensing data. Faced with the two distinct paths of supervised and unsupervised classification, I realised that the choice of classification method depends not only on the data itself, but also on the research objectives and the availability of resources. In particular, tools such as random forests and regression trees showed me the balance between accuracy and efficiency, which may play a great role in urban research in the future.\nIn particular, the ‚Äòmajority voting‚Äô mechanism of random forests gave me more confidence in the robustness and accuracy of the classification results. I started to think about how to use Random Forests to handle complex remote sensing data and capture the subtle differences in urban change in topics such as urban heat island and land use change. However, I also realised that the complexity of the Random Forest model itself makes the interpretation of the results potentially difficult, so in the future I will need to learn more about how to effectively interpret and communicate the results of classification models.\nThe presentation of regression trees, on the other hand, made me think further about the advantages of remote sensing in quantitatively analysing continuous environmental variables. This capability is particularly suited to the estimation of metrics such as urban vegetation percentage and surface temperature.\nOn the other hand, unsupervised classification methods such as K-means clustering enlightened me on how to be more flexible in preliminary data exploration, especially when the data are incomplete or under-labelled. However, I also noticed that determining the optimal number of classifications is still highly subjective, which also showed me how it is important to incorporate supervised classification strategies based on unsupervised classification in order to reduce subjective bias.\n\n\n\n\nBelgiu, M. and DrƒÉgu≈£, L. (2016) ‚ÄúRandom forest in remote sensing: A review of applications and future directions,‚Äù ISPRS Journal of Photogrammetry and Remote Sensing, 114, pp. 24‚Äì31. Available at: https://doi.org/10.1016/j.isprsjprs.2016.01.011.\n\n\nGao, Y. and Xu, X. (2016) ‚ÄúIntegration of k-means clustering and object-oriented classification for land-cover mapping,‚Äù Geocarto International, 31(6), pp. 620‚Äì632. Available at: https://doi.org/10.1080/10106049.2015.1064055.\n\n\nImhoff, M.L. et al. (2010) ‚ÄúRemote sensing of the urban heat island effect across biomes in the continental USA,‚Äù Remote Sensing of Environment, 114(3), pp. 504‚Äì513. Available at: https://doi.org/10.1016/j.rse.2009.10.008.",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Week 7 Diary</span>"
    ]
  },
  {
    "objectID": "Week8.html",
    "href": "Week8.html",
    "title": "7¬† Week 8 Diary",
    "section": "",
    "text": "8 Week 8: Classification and Accuracy Assessment",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Week 8 Diary</span>"
    ]
  },
  {
    "objectID": "Week8.html#summary",
    "href": "Week8.html#summary",
    "title": "7¬† Week 8 Diary",
    "section": "8.1 Summary",
    "text": "8.1 Summary\nThis week‚Äôs course continues to explore classification methods while focusing on accuracy assessment of remotely sensed imagery.We started with several surface coverage products, such as MODIS, GlobeLand30, and the hipster-named Dynamic World, which was developed by Google and Microsoft and uses Convolutional Neural Networks (CNN) and Sentinel-2 data to provide ‚Äòreal-time‚Äô and ‚Äòglobal coverage‚Äô.\nIt sounds pretty cool, but the professor immediately reminded us that although the data is new and fast, it also has a lot of problems, such as using Top Atmospheric Reflectance (TOA) to train the model, which may be mixed with atmospheric interference. In addition, its minimum mapping unit is 50√ó50 metres, which makes the classified images look a bit blurry and unsuitable for fine urban studies after convolution processing.\nWe then learnt about two more ‚Äòsmart‚Äô classification methods: Object-Oriented Image Analysis (OBIA) and Sub-pixel analysis.Instead of focusing on individual pixels, OBIA combines similar pixels into ‚Äúobjects‚Äù, which are analysed as a whole through spatial and spectral similarity ‚Äî somewhat like a geographical version of clustering algorithms.Sub-pixel classification, on the other hand, tries to estimate the proportion of different features within a single pixel. This approach is especially suitable for complex urban scenes, where a pixel may simultaneously contain grass, concrete, and water.\nThe most enlightening part was the accuracy assessment section. We learnt about producer accuracy, user accuracy, overall accuracy, and the classic ‚Äî but highly controversial ‚Äî Kappa coefficient.The professor emphasised that you can‚Äôt just look at a high value and assume that the model is good. Especially when the training and test data are too close, the classification accuracy is likely to be overestimated.This also made me realise that accuracy assessment is not only a technical task, but also a logical and methodological process ‚Äî one that requires careful consideration of data quality, sampling strategy, and model robustness.",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Week 8 Diary</span>"
    ]
  },
  {
    "objectID": "Week8.html#applications",
    "href": "Week8.html#applications",
    "title": "7¬† Week 8 Diary",
    "section": "8.2 Applications",
    "text": "8.2 Applications\nThis week‚Äôs study made me realise that the task of classifying urban remote sensing is often stuck between ‚Äúhow to classify more accurately‚Äù and ‚Äúhow to know if the classification is accurate.‚Äù Two methods are of particular interest to me: Object-Oriented Image Analysis (OBIA) and Spectral Mixture Analysis (SMA). When processing high-resolution remote sensing imagery, I have found that traditional pixel-level classification often results in a ‚Äúpretzel effect,‚Äù where the image appears to be sprinkled with noise. In contrast, the OBIA method better reflects the spatial continuity of real-world features by aggregating similar pixels into meaningful objects before classification. This approach not only improves the readability of the classified map but also reduces classification errors (Benz et al., 2004). I think it is especially important in urban areas, where green spaces or water bodies tend to form coherent patches rather than being randomly scattered.\n\n\n\n\n\nFig. 1 Example segmentation result in eCognition\nSource: Benz et al.¬†(2004)\nAnother thing that struck me was the SMA (Spectral Mixture Analysis) method. In urban areas, a pixel often contains multiple features, such as roofs, grass, and pavement mixed together. Traditional classification forces a ‚Äúpick one‚Äù approach, but SMA more reasonably assumes that each pixel is a combination of multiple features. By estimating the proportions of each component, we can obtain a more nuanced classification, which is particularly useful for assessing the proportion of urban green space cover or impervious surface (Small, 2003). \nFig. 2 False color composites and principal component representations of urban areas\nSource: Small (2003) \nFig. 3 Example applications of spectral mixture analysis on urban IKONOS imagery\nSource: Small (2003)\nThese two figures in particular help me to understand the strengths of Spectral Mixture Analysis (SMA): the consistency of SMA in revealing similar ‚Äúmixed structures‚Äù such as high-albedo buildings, vegetation, and shaded areas ‚Äî even in different cities ‚Äî suggests that it has a good ability to generalise.\nAfter the classification is done, the accuracy assessment is especially critical. In my opinion, high accuracy does not always mean that the model is good, especially if the training and validation samples are too close together spatially, and the model may ‚Äúleak‚Äù (Foody, 2002). I will be particularly concerned about the presence of spatial autocorrelation in future analyses.\nAfter reviewing the literature, I found that these methods are also widely used in real urban studies, as the SMA method can be used to estimate vegetation cover in Indianapolis, and the OBIA method has been used to monitor changes in urban tree canopy and feature boundaries (Lu and Weng, 2004). These ideas made me realise that what we are learning now is actually ‚Äúrunning‚Äù in real projects.",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Week 8 Diary</span>"
    ]
  },
  {
    "objectID": "Week8.html#reflection",
    "href": "Week8.html#reflection",
    "title": "7¬† Week 8 Diary",
    "section": "8.3 Reflection",
    "text": "8.3 Reflection\nThis week has made me realise that remote sensing classification is much more than just ‚Äòlabelling pixels‚Äô. Not only do we need to know how to classify, but we also need to really understand if and how the results can be trusted.\nIn the course, the professor emphasised the issue of spatial autocorrelation, which made me rethink my previous superstitions about high accuracy. In the past, when I saw ‚Äò95% accuracy‚Äô in the literature, I thought it was a proof that the model was great, but now I know that the reason behind it is that the training and testing samples may be ‚Äòtoo similar‚Äô to each other. This detail reminds me that remote sensing is not only a technology, but also a place to practice methodology and logic.\nI especially like the OBIA and SMA methods introduced this week, which both go beyond the simple assumption of ‚Äòone pixel equals one feature‚Äô and are closer to the complexity of the real world.\nThe idea of breaking down a pixel into its constituent parts, as in SMA, is not just a technical choice, but for me a cognitive shift: the objects we are analysing are not clearly distinguishable categories, but rather a continuum, a mixture of realities.\nThis started me thinking that in the future, if I were to engage in urban carbon stock assessment, urban sprawl monitoring, or heat island analysis, SMA or OBIA might provide more structured data support than traditional supervised classification.\nIn addition, I started to realise that accuracy assessment is not just a ‚Äòfinal step‚Äô, but something that should be considered from the very beginning of designing a sampling strategy. For example:\n- How to divide the training/validation samples?\n- Is there any spatial overlap?\n- Are the evaluation metrics serving my actual goals?\nThese questions may not have been a concern before, but now they will become ‚Äúreminder bells‚Äù in my project design.\nIn short, this week‚Äôs content has helped me move from ‚Äòusing the tool‚Äô to ‚Äòunderstanding the tool‚Äô, and given me more ‚Äòconfidence to question it‚Äô when facing remote sensing data in the future. I think this is an invaluable form of critical awareness.\n\n\n\n\nBenz, U.C. et al. (2004) ‚ÄúMulti-resolution, object-oriented fuzzy analysis of remote sensing data for GIS-ready information,‚Äù ISPRS Journal of Photogrammetry and Remote Sensing, 58(3-4), pp. 239‚Äì258.\n\n\nFoody, G.M. (2002) ‚ÄúStatus of land cover classification accuracy assessment,‚Äù Remote Sensing of Environment, 80(1), pp. 185‚Äì201.\n\n\nLu, D. and Weng, Q. (2004) ‚ÄúSpectral mixture analysis of the urban landscape in indianapolis with landsat ETM+ imagery,‚Äù Photogrammetric Engineering & Remote Sensing, 70(9), pp. 1053‚Äì1062.\n\n\nSmall, C. (2003) ‚ÄúHigh spatial resolution spectral mixture analysis of urban reflectance,‚Äù Remote Sensing of Environment, 88(1-2), pp. 170‚Äì186.",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Week 8 Diary</span>"
    ]
  }
]